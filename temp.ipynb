{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c20904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1/700 (class 0)...\n",
      " HSV mask foreground pixels: 130815\n",
      " After opening: 127755, After connected-component filtering: 121125\n",
      " After filling holes: 121125\n",
      "{'corner_count': 5553, 'circularity': 0.13930374202013132, 'aspect_ratio': 1.1388888888888888, 'extent': 0.3218157181571816, 'avg_hue': 21.752377321060976}\n",
      "Processing image 2/700 (class 0)...\n",
      " HSV mask foreground pixels: 20145\n",
      " After opening: 9690, After connected-component filtering: 0\n",
      " After filling holes: 0\n",
      "{'corner_count': 1321, 'circularity': 0.0, 'aspect_ratio': 1.0, 'extent': 0.0, 'avg_hue': 0.0}\n",
      "Processing image 3/700 (class 0)...\n",
      " HSV mask foreground pixels: 81345\n",
      " After opening: 55335, After connected-component filtering: 50745\n",
      " After filling holes: 50745\n",
      "{'corner_count': 4115, 'circularity': 0.1958420982267582, 'aspect_ratio': 0.8571428571428571, 'extent': 0.2961309523809524, 'avg_hue': 10.567092886763021}\n",
      "Processing image 4/700 (class 0)...\n",
      " HSV mask foreground pixels: 428655\n",
      " After opening: 427635, After connected-component filtering: 427635\n",
      " After filling holes: 427635\n",
      "{'corner_count': 7432, 'circularity': 0.09621686902020023, 'aspect_ratio': 1.0, 'extent': 0.314693188215425, 'avg_hue': 179.23407141440646}\n",
      "Processing image 5/700 (class 0)...\n",
      " HSV mask foreground pixels: 1742415\n",
      " After opening: 1713855, After connected-component filtering: 1672800\n",
      " After filling holes: 1672800\n",
      "{'corner_count': 7655, 'circularity': 0.06548291282611914, 'aspect_ratio': 1.0597014925373134, 'extent': 0.3447550977506832, 'avg_hue': 2.8763274595065127}\n",
      "Processing image 6/700 (class 0)...\n",
      " HSV mask foreground pixels: 173655\n",
      " After opening: 173655, After connected-component filtering: 173910\n",
      " After filling holes: 173910\n",
      "{'corner_count': 7711, 'circularity': 0.11843762190949482, 'aspect_ratio': 1.0, 'extent': 0.3367901234567901, 'avg_hue': 1.5686911669604342}\n",
      "Processing image 7/700 (class 0)...\n",
      " HSV mask foreground pixels: 407745\n",
      " After opening: 382245, After connected-component filtering: 365160\n",
      " After filling holes: 365160\n",
      "{'corner_count': 10420, 'circularity': 0.10009702474057904, 'aspect_ratio': 0.8985507246376812, 'extent': 0.33473585787751287, 'avg_hue': 2.0685299365724177}\n",
      "Processing image 8/700 (class 0)...\n",
      " HSV mask foreground pixels: 107355\n",
      " After opening: 101745, After connected-component filtering: 101745\n",
      " After filling holes: 101745\n",
      "{'corner_count': 6136, 'circularity': 0.18416829660713718, 'aspect_ratio': 1.0, 'extent': 0.41519250780437045, 'avg_hue': 8.22953118514829}\n",
      "Processing image 9/700 (class 0)...\n",
      " HSV mask foreground pixels: 353940\n",
      " After opening: 317220, After connected-component filtering: 317730\n",
      " After filling holes: 317730\n",
      "{'corner_count': 7668, 'circularity': 0.13952058619284055, 'aspect_ratio': 1.0, 'extent': 0.3579431197931629, 'avg_hue': 11.913813130064739}\n",
      "Processing image 10/700 (class 0)...\n",
      " HSV mask foreground pixels: 6885\n",
      " After opening: 0, After connected-component filtering: 0\n",
      " After filling holes: 0\n",
      "{'corner_count': 2905, 'circularity': 0.0, 'aspect_ratio': 1.0, 'extent': 0.0, 'avg_hue': 0.0}\n",
      "Processing image 11/700 (class 0)...\n",
      " HSV mask foreground pixels: 260865\n",
      " After opening: 235620, After connected-component filtering: 217260\n",
      " After filling holes: 217260\n",
      "{'corner_count': 8488, 'circularity': 0.12818988952998664, 'aspect_ratio': 0.9411764705882353, 'extent': 0.3480392156862745, 'avg_hue': 2.4733448068681696}\n",
      "Processing image 12/700 (class 0)...\n",
      " HSV mask foreground pixels: 230265\n",
      " After opening: 230010, After connected-component filtering: 230010\n",
      " After filling holes: 230010\n",
      "{'corner_count': 7494, 'circularity': 0.10100125902563577, 'aspect_ratio': 1.0, 'extent': 0.34678969627066514, 'avg_hue': 0.3163942482108837}\n",
      "Processing image 13/700 (class 0)...\n",
      " HSV mask foreground pixels: 403155\n",
      " After opening: 376125, After connected-component filtering: 362355\n",
      " After filling holes: 362355\n",
      "{'corner_count': 7738, 'circularity': 0.127661733556896, 'aspect_ratio': 0.859375, 'extent': 0.4036931818181818, 'avg_hue': 8.248990251630005}\n",
      "Processing image 14/700 (class 0)...\n",
      " HSV mask foreground pixels: 592365\n",
      " After opening: 591855, After connected-component filtering: 591855\n",
      " After filling holes: 591855\n",
      "{'corner_count': 6982, 'circularity': 0.0910441702229009, 'aspect_ratio': 1.0, 'extent': 0.3138182801514332, 'avg_hue': 178.59793152668897}\n",
      "Processing image 15/700 (class 0)...\n",
      " HSV mask foreground pixels: 108630\n",
      " After opening: 105825, After connected-component filtering: 99705\n",
      " After filling holes: 99705\n",
      "{'corner_count': 6233, 'circularity': 0.36514944338692307, 'aspect_ratio': 0.92, 'extent': 0.68, 'avg_hue': 12.80444958314473}\n",
      "Processing image 16/700 (class 0)...\n",
      " HSV mask foreground pixels: 147900\n",
      " After opening: 146625, After connected-component filtering: 136935\n",
      " After filling holes: 136935\n",
      "{'corner_count': 5794, 'circularity': 0.11913249452564925, 'aspect_ratio': 1.175, 'extent': 0.2856382978723404, 'avg_hue': 22.34861575784373}\n",
      "Processing image 17/700 (class 0)...\n",
      " HSV mask foreground pixels: 348330\n",
      " After opening: 320025, After connected-component filtering: 320025\n",
      " After filling holes: 320025\n",
      "{'corner_count': 9681, 'circularity': 0.10422079632715063, 'aspect_ratio': 0.9354838709677419, 'extent': 0.34899888765294773, 'avg_hue': 1.6842844692191647}\n",
      "Processing image 18/700 (class 0)...\n",
      " HSV mask foreground pixels: 65535\n",
      " After opening: 51510, After connected-component filtering: 49470\n",
      " After filling holes: 49470\n",
      "{'corner_count': 8421, 'circularity': 0.2943939016043569, 'aspect_ratio': 1.4, 'extent': 0.3464285714285714, 'avg_hue': 6.574609240880591}\n",
      "Processing image 19/700 (class 0)...\n",
      " HSV mask foreground pixels: 104805\n",
      " After opening: 99195, After connected-component filtering: 99960\n",
      " After filling holes: 99960\n",
      "{'corner_count': 7112, 'circularity': 0.1608495438637974, 'aspect_ratio': 1.0344827586206897, 'extent': 0.45057471264367815, 'avg_hue': 8.57551418912169}\n",
      "Processing image 20/700 (class 0)...\n",
      " HSV mask foreground pixels: 180795\n",
      " After opening: 179265, After connected-component filtering: 179520\n",
      " After filling holes: 179520\n",
      "{'corner_count': 7768, 'circularity': 0.12597685884669074, 'aspect_ratio': 1.0, 'extent': 0.3476543209876543, 'avg_hue': 1.5317819620398723}\n",
      "Processing image 21/700 (class 0)...\n",
      " HSV mask foreground pixels: 457725\n",
      " After opening: 400860, After connected-component filtering: 398565\n",
      " After filling holes: 398565\n",
      "{'corner_count': 8284, 'circularity': 0.10874041395290455, 'aspect_ratio': 0.9701492537313433, 'extent': 0.35889781859931114, 'avg_hue': 11.99963805054142}\n",
      "Processing image 22/700 (class 0)...\n",
      " HSV mask foreground pixels: 78285\n",
      " After opening: 78285, After connected-component filtering: 78795\n",
      " After filling holes: 78795\n",
      "{'corner_count': 6792, 'circularity': 0.1846853041539588, 'aspect_ratio': 0.967741935483871, 'extent': 0.33225806451612905, 'avg_hue': 12.309219585147503}\n",
      "Processing image 23/700 (class 0)...\n",
      " HSV mask foreground pixels: 49980\n",
      " After opening: 41055, After connected-component filtering: 39525\n",
      " After filling holes: 39525\n",
      "{'corner_count': 8046, 'circularity': 0.3372208180792368, 'aspect_ratio': 1.9230769230769231, 'extent': 0.47692307692307695, 'avg_hue': 5.820627999053215}\n",
      "Processing image 24/700 (class 0)...\n",
      " HSV mask foreground pixels: 666315\n",
      " After opening: 618375, After connected-component filtering: 597720\n",
      " After filling holes: 597720\n",
      "{'corner_count': 9520, 'circularity': 0.08461813478902011, 'aspect_ratio': 1.0389610389610389, 'extent': 0.38051948051948054, 'avg_hue': 3.77936467929311}\n",
      "Processing image 25/700 (class 0)...\n",
      " HSV mask foreground pixels: 37995\n",
      " After opening: 9945, After connected-component filtering: 0\n",
      " After filling holes: 0\n",
      "{'corner_count': 3343, 'circularity': 0.0, 'aspect_ratio': 1.0, 'extent': 0.0, 'avg_hue': 0.0}\n",
      "Processing image 26/700 (class 0)...\n",
      " HSV mask foreground pixels: 57630\n",
      " After opening: 42840, After connected-component filtering: 39780\n",
      " After filling holes: 39780\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv('dataset/Train.csv')\n",
    "\n",
    "# Select N classes (example: 6 classes)\n",
    "selected_classes = [0, 1, 2, 3, 4, 5, 6]\n",
    "subset_df = df[df['ClassId'].isin(selected_classes)]\n",
    "\n",
    "# Sample 100 images from each class\n",
    "sampled_df = subset_df.groupby('ClassId').apply(lambda x: x.sample(n=100, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "class TrafficSignClassifier:\n",
    "    def __init__(self):\n",
    "        # Store preprocessed images, features, etc.\n",
    "        self.processed_images = {}\n",
    "        self.features = {}\n",
    "        self.labels = {}\n",
    "        self.class_names = {\n",
    "            0: \"Speed Limit 20 km/h\",\n",
    "            1: \"Speed Limit 30 km/h\",\n",
    "            2: \"Speed Limit 50 km/h\",\n",
    "            3: \"Speed Limit 60 km/h\",\n",
    "            4: \"Speed Limit 70 km/h\",\n",
    "            5: \"Speed Limit 80 km/h\",\n",
    "            6: \"End of Speed Limit 80 km/h\"\n",
    "        }\n",
    "    \n",
    "    # ==================== PREPROCESSING FILTERS ====================\n",
    "    \n",
    "    def mean_filter(self, image, kernel_size=3):\n",
    "        \"\"\"Apply mean filter using NumPy operations.\"\"\"\n",
    "        if len(image.shape) == 3:  # Color image\n",
    "            height, width, channels = image.shape\n",
    "            result = np.zeros_like(image, dtype=np.uint8)\n",
    "            pad_size = kernel_size // 2\n",
    "            \n",
    "            # Pad the image\n",
    "            padded = np.pad(image, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='reflect')\n",
    "            \n",
    "            # Apply filter\n",
    "            for c in range(channels):\n",
    "                for i in range(height):\n",
    "                    for j in range(width):\n",
    "                        window = padded[i:i+kernel_size, j:j+kernel_size, c]\n",
    "                        result[i, j, c] = np.mean(window)\n",
    "                        \n",
    "        else:  # Grayscale image\n",
    "            height, width = image.shape\n",
    "            result = np.zeros_like(image, dtype=np.uint8)\n",
    "            pad_size = kernel_size // 2\n",
    "            \n",
    "            # Pad the image\n",
    "            padded = np.pad(image, ((pad_size, pad_size), (pad_size, pad_size)), mode='reflect')\n",
    "            \n",
    "            # Apply filter\n",
    "            for i in range(height):\n",
    "                for j in range(width):\n",
    "                    window = padded[i:i+kernel_size, j:j+kernel_size]\n",
    "                    result[i, j] = np.mean(window)\n",
    "                    \n",
    "        return result\n",
    "    \n",
    "    def gaussian_filter(self, image, kernel_size=3, sigma=1.0):\n",
    "        \"\"\"Apply Gaussian filter using NumPy operations.\"\"\"\n",
    "        # Create Gaussian kernel\n",
    "        k = kernel_size // 2\n",
    "        x, y = np.mgrid[-k:k+1, -k:k+1]\n",
    "        normal = 1 / (2.0 * np.pi * sigma**2)\n",
    "        kernel = np.exp(-((x**2 + y**2) / (2.0 * sigma**2))) * normal\n",
    "        kernel = kernel / np.sum(kernel)  # Normalize\n",
    "        \n",
    "        if len(image.shape) == 3:  # Color image\n",
    "            height, width, channels = image.shape\n",
    "            result = np.zeros_like(image, dtype=np.float32)\n",
    "            pad_size = kernel_size // 2\n",
    "            \n",
    "            # Pad the image\n",
    "            padded = np.pad(image, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='reflect')\n",
    "            \n",
    "            # Apply filter\n",
    "            for c in range(channels):\n",
    "                for i in range(height):\n",
    "                    for j in range(width):\n",
    "                        window = padded[i:i+kernel_size, j:j+kernel_size, c]\n",
    "                        result[i, j, c] = np.sum(window * kernel)\n",
    "                        \n",
    "        else:  # Grayscale image\n",
    "            height, width = image.shape\n",
    "            result = np.zeros_like(image, dtype=np.float32)\n",
    "            pad_size = kernel_size // 2\n",
    "            \n",
    "            # Pad the image\n",
    "            padded = np.pad(image, ((pad_size, pad_size), (pad_size, pad_size)), mode='reflect')\n",
    "            \n",
    "            # Apply filter\n",
    "            for i in range(height):\n",
    "                for j in range(width):\n",
    "                    window = padded[i:i+kernel_size, j:j+kernel_size]\n",
    "                    result[i, j] = np.sum(window * kernel)\n",
    "        \n",
    "        return np.clip(result, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    def median_filter(self, image, kernel_size=3):\n",
    "        \"\"\"Apply median filter using NumPy operations.\"\"\"\n",
    "        if len(image.shape) == 3:  # Color image\n",
    "            height, width, channels = image.shape\n",
    "            result = np.zeros_like(image, dtype=np.uint8)\n",
    "            pad_size = kernel_size // 2\n",
    "            \n",
    "            # Pad the image\n",
    "            padded = np.pad(image, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='reflect')\n",
    "            \n",
    "            # Apply filter\n",
    "            for c in range(channels):\n",
    "                for i in range(height):\n",
    "                    for j in range(width):\n",
    "                        window = padded[i:i+kernel_size, j:j+kernel_size, c]\n",
    "                        result[i, j, c] = np.median(window)\n",
    "                        \n",
    "        else:  # Grayscale image\n",
    "            height, width = image.shape\n",
    "            result = np.zeros_like(image, dtype=np.uint8)\n",
    "            pad_size = kernel_size // 2\n",
    "            \n",
    "            # Pad the image\n",
    "            padded = np.pad(image, ((pad_size, pad_size), (pad_size, pad_size)), mode='reflect')\n",
    "            \n",
    "            # Apply filter\n",
    "            for i in range(height):\n",
    "                for j in range(width):\n",
    "                    window = padded[i:i+kernel_size, j:j+kernel_size]\n",
    "                    result[i, j] = np.median(window)\n",
    "                    \n",
    "        return result\n",
    "    \n",
    "    def adaptive_median_filter(self, image, max_kernel_size=7):\n",
    "        \"\"\"Apply adaptive median filter using NumPy operations.\"\"\"\n",
    "        if len(image.shape) == 3:  # Color image\n",
    "            height, width, channels = image.shape\n",
    "            result = np.zeros_like(image, dtype=np.uint8)\n",
    "            \n",
    "            for c in range(channels):\n",
    "                for i in range(height):\n",
    "                    for j in range(width):\n",
    "                        pixel_value = self._adaptive_median_process(image[:,:,c], i, j, max_kernel_size)\n",
    "                        result[i, j, c] = pixel_value\n",
    "                        \n",
    "        else:  # Grayscale image\n",
    "            height, width = image.shape\n",
    "            result = np.zeros_like(image, dtype=np.uint8)\n",
    "            \n",
    "            for i in range(height):\n",
    "                for j in range(width):\n",
    "                    result[i, j] = self._adaptive_median_process(image, i, j, max_kernel_size)\n",
    "                    \n",
    "        return result\n",
    "    \n",
    "    def _adaptive_median_process(self, image, i, j, max_size):\n",
    "        \"\"\"Helper function for adaptive median filter.\"\"\"\n",
    "        kernel_size = 3  # Start with 3x3 window\n",
    "        \n",
    "        while kernel_size <= max_size:\n",
    "            pad_size = kernel_size // 2\n",
    "            h, w = image.shape\n",
    "            \n",
    "            # Ensure we don't go out of bounds\n",
    "            i_min = max(0, i - pad_size)\n",
    "            i_max = min(h, i + pad_size + 1)\n",
    "            j_min = max(0, j - pad_size)\n",
    "            j_max = min(w, j + pad_size + 1)\n",
    "            \n",
    "            window = image[i_min:i_max, j_min:j_max]\n",
    "            window_flat = window.flatten()\n",
    "            \n",
    "            z_min = np.min(window_flat)\n",
    "            z_max = np.max(window_flat)\n",
    "            z_med = np.median(window_flat)\n",
    "            z_xy = image[i, j]\n",
    "            \n",
    "            # Stage A\n",
    "            if z_med > z_min and z_med < z_max:\n",
    "                # Stage B\n",
    "                if z_xy > z_min and z_xy < z_max:\n",
    "                    return z_xy\n",
    "                else:\n",
    "                    return z_med\n",
    "            else:\n",
    "                # Increase kernel size and try again\n",
    "                kernel_size += 2\n",
    "                if kernel_size > max_size:\n",
    "                    return z_med\n",
    "    \n",
    "    def unsharp_masking(self, image, kernel_size=5, alpha=1.5):\n",
    "        \"\"\"Apply unsharp masking for edge enhancement.\"\"\"\n",
    "        # Apply Gaussian filter to create blurred image\n",
    "        blurred = self.gaussian_filter(image, kernel_size=kernel_size, sigma=1.0)\n",
    "        \n",
    "        # Calculate the mask (original - blurred)\n",
    "        if len(image.shape) == 3:\n",
    "            mask = image.astype(np.float32) - blurred.astype(np.float32)\n",
    "            # Apply high-boost filtering (original + alpha * mask)\n",
    "            sharpened = image.astype(np.float32) + alpha * mask\n",
    "        else:\n",
    "            mask = image.astype(np.float32) - blurred.astype(np.float32)\n",
    "            sharpened = image.astype(np.float32) + alpha * mask\n",
    "            \n",
    "        # Clip values to valid range\n",
    "        return np.clip(sharpened, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # ==================== COLOR SPACE CONVERSION ====================\n",
    "    \n",
    "    def rgb_to_hsv(self, rgb_img):\n",
    "        \"\"\"\n",
    "        Convert RGB image to HSV color space manually using NumPy operations.\n",
    "        Input: RGB image with values in range [0, 255]\n",
    "        Output: HSV image with H in [0, 180), S in [0, 255], V in [0, 255]\n",
    "        \"\"\"\n",
    "        # Normalize RGB values to [0, 1]\n",
    "        rgb_normalized = rgb_img.astype(np.float32) / 255.0\n",
    "        \n",
    "        r, g, b = rgb_normalized[:,:,0], rgb_normalized[:,:,1], rgb_normalized[:,:,2]\n",
    "        \n",
    "        # Value (V) is the maximum of R, G, B\n",
    "        v = np.max(rgb_normalized, axis=2)\n",
    "        \n",
    "        # Calculate delta (difference between max and min RGB values)\n",
    "        min_rgb = np.min(rgb_normalized, axis=2)\n",
    "        delta = v - min_rgb\n",
    "        \n",
    "        # Initialize HSV arrays\n",
    "        h = np.zeros_like(r)\n",
    "        s = np.zeros_like(r)\n",
    "        \n",
    "        # Calculate Saturation (S)\n",
    "        # If V is 0, S is also 0\n",
    "        s = np.where(v != 0, delta / np.maximum(v, 1e-10), 0)\n",
    "        \n",
    "        # Calculate Hue (H)\n",
    "        # If delta is 0, H is undefined (we'll set it to 0)\n",
    "        # Otherwise, calculate based on which channel is max\n",
    "        \n",
    "        # For pixels where R is max\n",
    "        r_max_mask = (v == r) & (delta != 0)\n",
    "        h[r_max_mask] = 60 * (((g[r_max_mask] - b[r_max_mask]) / delta[r_max_mask]) % 6)\n",
    "        \n",
    "        # For pixels where G is max\n",
    "        g_max_mask = (v == g) & (delta != 0)\n",
    "        h[g_max_mask] = 60 * (((b[g_max_mask] - r[g_max_mask]) / delta[g_max_mask]) + 2)\n",
    "        \n",
    "        # For pixels where B is max\n",
    "        b_max_mask = (v == b) & (delta != 0)\n",
    "        h[b_max_mask] = 60 * (((r[b_max_mask] - g[b_max_mask]) / delta[b_max_mask]) + 4)\n",
    "        \n",
    "        # Ensure H is in [0, 180) range for OpenCV compatibility\n",
    "        h = h / 2.0\n",
    "        \n",
    "        # Scale S and V to [0, 255]\n",
    "        s = s * 255.0\n",
    "        v = v * 255.0\n",
    "        \n",
    "        # Stack channels and convert to uint8\n",
    "        hsv_img = np.stack([h, s, v], axis=2).astype(np.uint8)\n",
    "        \n",
    "        return hsv_img\n",
    "    \n",
    "    # ==================== SEGMENTATION ====================\n",
    "    \n",
    "    def segment_by_color(self, hsv_img):\n",
    "        \"\"\"\n",
    "        Segment the image based on color ranges for traffic signs.\n",
    "        Returns a binary mask.\n",
    "        \"\"\"\n",
    "        h, s, v = hsv_img[:,:,0], hsv_img[:,:,1], hsv_img[:,:,2]\n",
    "        \n",
    "        # Red signs (wrap around hue)\n",
    "        mask_red_low = (h <= 15) & (s > 70) & (v > 50)\n",
    "        mask_red_high = (h >= 165) & (s > 70) & (v > 50)\n",
    "        mask_red = mask_red_low | mask_red_high\n",
    "        \n",
    "        # Blue signs\n",
    "        mask_blue = (h >= 100) & (h <= 130) & (s > 70) & (v > 50)\n",
    "        \n",
    "        # Combined mask\n",
    "        mask = mask_red | mask_blue\n",
    "        \n",
    "        # Convert to binary uint8\n",
    "        return mask.astype(np.uint8) * 255\n",
    "    \n",
    "    # ==================== MORPHOLOGICAL OPERATIONS ====================\n",
    "    \n",
    "    def erode(self, binary_img, kernel_size=3):\n",
    "        \"\"\"Apply erosion to a binary image.\"\"\"\n",
    "        height, width = binary_img.shape\n",
    "        result = np.zeros_like(binary_img)\n",
    "        pad_size = kernel_size // 2\n",
    "        \n",
    "        # Pad the image\n",
    "        padded = np.pad(binary_img, ((pad_size, pad_size), (pad_size, pad_size)), mode='constant')\n",
    "        \n",
    "        # Apply erosion\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                window = padded[i:i+kernel_size, j:j+kernel_size]\n",
    "                # For erosion, all pixels must be 255 (white)\n",
    "                if np.all(window == 255):\n",
    "                    result[i, j] = 255\n",
    "                else:\n",
    "                    result[i, j] = 0\n",
    "                    \n",
    "        return result\n",
    "    \n",
    "    def dilate(self, binary_img, kernel_size=3):\n",
    "        \"\"\"Apply dilation to a binary image.\"\"\"\n",
    "        height, width = binary_img.shape\n",
    "        result = np.zeros_like(binary_img)\n",
    "        pad_size = kernel_size // 2\n",
    "        \n",
    "        # Pad the image\n",
    "        padded = np.pad(binary_img, ((pad_size, pad_size), (pad_size, pad_size)), mode='constant')\n",
    "        \n",
    "        # Apply dilation\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                window = padded[i:i+kernel_size, j:j+kernel_size]\n",
    "                # For dilation, at least one pixel must be 255 (white)\n",
    "                if np.any(window == 255):\n",
    "                    result[i, j] = 255\n",
    "                else:\n",
    "                    result[i, j] = 0\n",
    "                    \n",
    "        return result\n",
    "    \n",
    "    def opening(self, binary_img, kernel_size=3):\n",
    "        \"\"\"Apply opening (erosion followed by dilation).\"\"\"\n",
    "        eroded = self.erode(binary_img, kernel_size)\n",
    "        return self.dilate(eroded, kernel_size)\n",
    "    \n",
    "    def closing(self, binary_img, kernel_size=3):\n",
    "        \"\"\"Apply closing (dilation followed by erosion).\"\"\"\n",
    "        dilated = self.dilate(binary_img, kernel_size)\n",
    "        return self.erode(dilated, kernel_size)\n",
    "    \n",
    "    def remove_small_components(self, binary_img, min_area=100):\n",
    "        \"\"\"Remove small connected components.\"\"\"\n",
    "        # Find connected components\n",
    "        labeled, num_features = self.connected_components(binary_img)\n",
    "        \n",
    "        # Calculate area of each component\n",
    "        areas = np.zeros(num_features + 1, dtype=int)\n",
    "        for i in range(binary_img.shape[0]):\n",
    "            for j in range(binary_img.shape[1]):\n",
    "                if labeled[i, j] > 0:\n",
    "                    areas[labeled[i, j]] += 1\n",
    "        \n",
    "        # Create new image with only components larger than min_area\n",
    "        result = np.zeros_like(binary_img)\n",
    "        for i in range(binary_img.shape[0]):\n",
    "            for j in range(binary_img.shape[1]):\n",
    "                if labeled[i, j] > 0 and areas[labeled[i, j]] >= min_area:\n",
    "                    result[i, j] = 255\n",
    "                    \n",
    "        return result\n",
    "    \n",
    "    def connected_components(self, binary_img):\n",
    "        \"\"\"Perform connected component labeling using 8-connectivity.\"\"\"\n",
    "        # Ensure the input is binary\n",
    "        binary = (binary_img > 0).astype(np.uint8)\n",
    "        \n",
    "        height, width = binary.shape\n",
    "        # Initialize labeled image with zeros\n",
    "        labeled = np.zeros((height, width), dtype=np.int32)\n",
    "        \n",
    "        # Create a padded version to handle border\n",
    "        padded = np.pad(binary, ((1, 1), (1, 1)), mode='constant')\n",
    "        \n",
    "        # Union-find data structure\n",
    "        parent = {}\n",
    "        \n",
    "        # First pass: assign temporary labels\n",
    "        next_label = 1\n",
    "        \n",
    "        for i in range(1, height + 1):\n",
    "            for j in range(1, width + 1):\n",
    "                if padded[i, j] == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Check neighbors (8-connectivity)\n",
    "                neighbors = []\n",
    "                if padded[i-1, j-1] > 0 and labeled[i-2, j-2] > 0:\n",
    "                    neighbors.append(labeled[i-2, j-2])\n",
    "                if padded[i-1, j] > 0 and labeled[i-2, j-1] > 0:\n",
    "                    neighbors.append(labeled[i-2, j-1])\n",
    "                if padded[i-1, j+1] > 0 and labeled[i-2, j] > 0:\n",
    "                    neighbors.append(labeled[i-2, j])\n",
    "                if padded[i, j-1] > 0 and labeled[i-1, j-2] > 0:\n",
    "                    neighbors.append(labeled[i-1, j-2])\n",
    "                \n",
    "                if not neighbors:\n",
    "                    # No neighbors with labels, assign new label\n",
    "                    labeled[i-1, j-1] = next_label\n",
    "                    parent[next_label] = next_label\n",
    "                    next_label += 1\n",
    "                else:\n",
    "                    # Assign smallest neighbor label\n",
    "                    min_label = min(neighbors)\n",
    "                    labeled[i-1, j-1] = min_label\n",
    "                    \n",
    "                    # Union all neighbor labels\n",
    "                    for l in neighbors:\n",
    "                        self._union(parent, l, min_label)\n",
    "        \n",
    "        # Find final labels (compress paths)\n",
    "        final_labels = {}\n",
    "        next_final_label = 1\n",
    "        \n",
    "        # Second pass: resolve labels\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                if labeled[i, j] > 0:\n",
    "                    root = self._find(parent, labeled[i, j])\n",
    "                    if root not in final_labels:\n",
    "                        final_labels[root] = next_final_label\n",
    "                        next_final_label += 1\n",
    "                    labeled[i, j] = final_labels[root]\n",
    "        \n",
    "        return labeled, len(final_labels)\n",
    "    \n",
    "    def _find(self, parent, x):\n",
    "        \"\"\"Find root with path compression (for union-find).\"\"\"\n",
    "        if parent[x] != x:\n",
    "            parent[x] = self._find(parent, parent[x])\n",
    "        return parent[x]\n",
    "    \n",
    "    def _union(self, parent, x, y):\n",
    "        \"\"\"Unite two sets by rank (for union-find).\"\"\"\n",
    "        root_x = self._find(parent, x)\n",
    "        root_y = self._find(parent, y)\n",
    "        \n",
    "        if root_x != root_y:\n",
    "            parent[root_x] = root_y\n",
    "    \n",
    "    def fill_holes(self, binary_img):\n",
    "        \"\"\"Fill holes in binary image using flood fill from borders.\"\"\"\n",
    "        # Create a padded image with a 1-pixel border of zeros\n",
    "        h, w = binary_img.shape\n",
    "        padded = np.pad(binary_img, ((1, 1), (1, 1)), mode='constant')\n",
    "        \n",
    "        # Create a mask image initialized to 255 (white)\n",
    "        mask = np.ones((h+2, w+2), dtype=np.uint8) * 255\n",
    "        \n",
    "        # Set original object to 0 (black) in the mask\n",
    "        mask[1:-1, 1:-1][binary_img > 0] = 0\n",
    "        \n",
    "        # Initialize queue with border pixels\n",
    "        queue = []\n",
    "        for i in range(h+2):\n",
    "            queue.append((i, 0))\n",
    "            queue.append((i, w+1))\n",
    "        for j in range(1, w+1):\n",
    "            queue.append((0, j))\n",
    "            queue.append((h+1, j))\n",
    "        \n",
    "        # Perform flood fill starting from the border\n",
    "        while queue:\n",
    "            i, j = queue.pop(0)\n",
    "            if 0 <= i < h+2 and 0 <= j < w+2 and mask[i, j] == 255:\n",
    "                mask[i, j] = 128  # Mark as visited\n",
    "                # Add neighbors to queue\n",
    "                queue.append((i+1, j))\n",
    "                queue.append((i-1, j))\n",
    "                queue.append((i, j+1))\n",
    "                queue.append((i, j-1))\n",
    "        \n",
    "        # Now mask contains: 0 = original object, 128 = background, 255 = holes\n",
    "        # Invert the result to get filled image (background and original object = 0, holes = 255)\n",
    "        filled = (mask == 0).astype(np.uint8) * 255\n",
    "        filled[1:-1,1:-1] = np.maximum(filled[1:-1,1:-1], binary_img)\n",
    "        \n",
    "        return filled[1:-1, 1:-1]  # Remove padding\n",
    "    \n",
    "    # ==================== EDGE DETECTION ====================\n",
    "    \n",
    "    def sobel_operator(self, image):\n",
    "        \"\"\"Apply Sobel operator for gradient computation.\"\"\"\n",
    "        # Convert to grayscale if needed\n",
    "        if len(image.shape) == 3:\n",
    "            gray = np.mean(image, axis=2).astype(np.uint8)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        # Define Sobel kernels\n",
    "        sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
    "        sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32)\n",
    "        \n",
    "        height, width = gray.shape\n",
    "        gradient_x = np.zeros_like(gray, dtype=np.float32)\n",
    "        gradient_y = np.zeros_like(gray, dtype=np.float32)\n",
    "        \n",
    "        # Pad image\n",
    "        padded = np.pad(gray, ((1, 1), (1, 1)), mode='reflect')\n",
    "        \n",
    "        # Apply kernels\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                window = padded[i:i+3, j:j+3].astype(np.float32)\n",
    "                gradient_x[i, j] = np.sum(window * sobel_x)\n",
    "                gradient_y[i, j] = np.sum(window * sobel_y)\n",
    "        \n",
    "        # Calculate gradient magnitude and direction\n",
    "        gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "        gradient_direction = np.arctan2(gradient_y, gradient_x)\n",
    "        \n",
    "        return gradient_magnitude, gradient_direction\n",
    "    \n",
    "    def non_maximum_suppression(self, gradient_magnitude, gradient_direction):\n",
    "        \"\"\"Apply non-maximum suppression to thin edges.\"\"\"\n",
    "        height, width = gradient_magnitude.shape\n",
    "        result = np.zeros_like(gradient_magnitude)\n",
    "        \n",
    "        # Convert radians to degrees and take absolute value\n",
    "        degrees = np.degrees(gradient_direction) % 180\n",
    "        \n",
    "        for i in range(1, height-1):\n",
    "            for j in range(1, width-1):\n",
    "                # Get angle in [0, 45, 90, 135]\n",
    "                angle = degrees[i, j]\n",
    "                \n",
    "                # Determine neighbors based on the angle\n",
    "                if (0 <= angle < 22.5) or (157.5 <= angle <= 180):  # Horizontal edge\n",
    "                    neighbors = [gradient_magnitude[i, j-1], gradient_magnitude[i, j+1]]\n",
    "                elif 22.5 <= angle < 67.5:  # Diagonal (/)\n",
    "                    neighbors = [gradient_magnitude[i+1, j-1], gradient_magnitude[i-1, j+1]]\n",
    "                elif 67.5 <= angle < 112.5:  # Vertical edge\n",
    "                    neighbors = [gradient_magnitude[i-1, j], gradient_magnitude[i+1, j]]\n",
    "                else:  # Diagonal (\\)\n",
    "                    neighbors = [gradient_magnitude[i-1, j-1], gradient_magnitude[i+1, j+1]]\n",
    "                \n",
    "                # If current pixel is a local maximum, keep it\n",
    "                if gradient_magnitude[i, j] >= max(neighbors):\n",
    "                    result[i, j] = gradient_magnitude[i, j]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def double_thresholding(self, img, low_threshold_ratio=0.05, high_threshold_ratio=0.15):\n",
    "        \"\"\"Apply double thresholding to identify strong, weak, and non-edges.\"\"\"\n",
    "        high_threshold = img.max() * high_threshold_ratio\n",
    "        low_threshold = high_threshold * low_threshold_ratio\n",
    "        \n",
    "        strong_edges = (img >= high_threshold)\n",
    "        weak_edges = (img >= low_threshold) & (img < high_threshold)\n",
    "        \n",
    "        # Create image with strong edges as 255, weak edges as 50, others as 0\n",
    "        result = np.zeros_like(img, dtype=np.uint8)\n",
    "        result[strong_edges] = 255\n",
    "        result[weak_edges] = 50\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def edge_tracking(self, img):\n",
    "        \"\"\"Track edges by hysteresis, converting weak edges to strong if connected.\"\"\"\n",
    "        height, width = img.shape\n",
    "        \n",
    "        # Function to recursively check neighbors and convert them\n",
    "        def check_neighbors(i, j):\n",
    "            if not (0 <= i < height and 0 <= j < width) or visited[i, j]:\n",
    "                return\n",
    "            \n",
    "            visited[i, j] = True\n",
    "            \n",
    "            if img[i, j] == 50:  # Weak edge\n",
    "                img[i, j] = 255  # Convert to strong edge\n",
    "                \n",
    "                # Check 8-connected neighbors\n",
    "                for di in [-1, 0, 1]:\n",
    "                    for dj in [-1, 0, 1]:\n",
    "                        if di == 0 and dj == 0:\n",
    "                            continue\n",
    "                        check_neighbors(i + di, j + dj)\n",
    "        \n",
    "        # Mark all pixels as unvisited\n",
    "        visited = np.zeros((height, width), dtype=bool)\n",
    "        \n",
    "        # Start tracking from strong edges\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                if img[i, j] == 255 and not visited[i, j]:\n",
    "                    check_neighbors(i, j)\n",
    "        \n",
    "        # Convert any remaining weak edges to non-edges\n",
    "        img[img != 255] = 0\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def canny_edge_detection(self, image, low_threshold_ratio=0.05, high_threshold_ratio=0.15):\n",
    "        \"\"\"Implement full Canny edge detection algorithm.\"\"\"\n",
    "        # Step 1: Noise reduction (already included in preprocessing)\n",
    "        smoothed = self.gaussian_filter(image, kernel_size=5, sigma=1.4)\n",
    "        \n",
    "        # Step 2: Gradient calculation\n",
    "        gradient_magnitude, gradient_direction = self.sobel_operator(smoothed)\n",
    "        \n",
    "        # Step 3: Non-maximum suppression\n",
    "        suppressed = self.non_maximum_suppression(gradient_magnitude, gradient_direction)\n",
    "        \n",
    "        # Step 4: Double thresholding\n",
    "        thresholded = self.double_thresholding(suppressed, low_threshold_ratio, high_threshold_ratio)\n",
    "        \n",
    "        # Step 5: Edge tracking by hysteresis\n",
    "        edges = self.edge_tracking(thresholded)\n",
    "        \n",
    "        return edges\n",
    "    \n",
    "    # ==================== GEOMETRIC NORMALIZATION ====================\n",
    "    \n",
    "    def rotate_image(self, image, angle_degrees):\n",
    "        \"\"\"Rotate image by the given angle in degrees.\"\"\"\n",
    "        # Convert angle to radians\n",
    "        angle_rad = np.radians(angle_degrees)\n",
    "        \n",
    "        height, width = image.shape[:2]\n",
    "        center_y, center_x = height // 2, width // 2\n",
    "        \n",
    "        # Define rotation matrix\n",
    "        cos_theta = np.cos(angle_rad)\n",
    "        sin_theta = np.sin(angle_rad)\n",
    "        \n",
    "        # Calculate new image dimensions\n",
    "        new_height = int(abs(height * cos_theta) + abs(width * sin_theta))\n",
    "        new_width = int(abs(width * cos_theta) + abs(height * sin_theta))\n",
    "        \n",
    "        # Create output image\n",
    "        if len(image.shape) == 3:\n",
    "            rotated = np.zeros((new_height, new_width, image.shape[2]), dtype=np.uint8)\n",
    "        else:\n",
    "            rotated = np.zeros((new_height, new_width), dtype=np.uint8)\n",
    "        \n",
    "        # Calculate offset to center the rotated image\n",
    "        offset_x = (new_width - width) // 2\n",
    "        offset_y = (new_height - height) // 2\n",
    "        \n",
    "        # Perform rotation using inverse mapping\n",
    "        for y in range(new_height):\n",
    "            for x in range(new_width):\n",
    "                # Convert to origin-centered coordinates\n",
    "                y_centered = y - new_height // 2\n",
    "                x_centered = x - new_width // 2\n",
    "                \n",
    "                # Apply inverse rotation\n",
    "                src_y = int(y_centered * cos_theta - x_centered * sin_theta + center_y)\n",
    "                src_x = int(x_centered * cos_theta + y_centered * sin_theta + center_x)\n",
    "                \n",
    "                # Check if source coordinates are valid\n",
    "                if 0 <= src_y < height and 0 <= src_x < width:\n",
    "                    if len(image.shape) == 3:\n",
    "                        rotated[y, x] = image[src_y, src_x]\n",
    "                    else:\n",
    "                        rotated[y, x] = image[src_y, src_x]\n",
    "        \n",
    "        return rotated\n",
    "    \n",
    "    def scale_image(self, image, target_size):\n",
    "        \"\"\"Scale the image to target size (width, height).\"\"\"\n",
    "        target_width, target_height = target_size\n",
    "        orig_height, orig_width = image.shape[:2]\n",
    "        \n",
    "        # Create output image\n",
    "        if len(image.shape) == 3:\n",
    "            scaled = np.zeros((target_height, target_width, image.shape[2]), dtype=np.uint8)\n",
    "        else:\n",
    "            scaled = np.zeros((target_height, target_width), dtype=np.uint8)\n",
    "        \n",
    "        # Calculate scaling factors\n",
    "        scale_x = orig_width / target_width\n",
    "        scale_y = orig_height / target_height\n",
    "        \n",
    "        # Perform scaling using inverse mapping\n",
    "        for y in range(target_height):\n",
    "            for x in range(target_width):\n",
    "                # Calculate source coordinates\n",
    "                src_y = int(y * scale_y)\n",
    "                src_x = int(x * scale_x)\n",
    "                \n",
    "                # Ensure we stay within bounds\n",
    "                src_y = min(src_y, orig_height - 1)\n",
    "                src_x = min(src_x, orig_width - 1)\n",
    "                \n",
    "                # Copy pixel value\n",
    "                if len(image.shape) == 3:\n",
    "                    scaled[y, x] = image[src_y, src_x]\n",
    "                else:\n",
    "                    scaled[y, x] = image[src_y, src_x]\n",
    "        \n",
    "        return scaled\n",
    "    \n",
    "    def normalize_geometry(self, image, mask, target_size=(200, 200)):\n",
    "        \"\"\"Normalize geometry of the traffic sign.\"\"\"\n",
    "        # Find contours/boundaries\n",
    "        edges = self.canny_edge_detection(mask)\n",
    "        \n",
    "        # Find center of mass\n",
    "        y_indices, x_indices = np.where(mask > 0)\n",
    "        if len(y_indices) == 0 or len(x_indices) == 0:\n",
    "            # If mask is empty, just scale the image\n",
    "            return self.scale_image(image, target_size)\n",
    "            \n",
    "        center_y = int(np.mean(y_indices))\n",
    "        center_x = int(np.mean(x_indices))\n",
    "        \n",
    "        # Find orientation using moments\n",
    "        # Calculate central moments\n",
    "        m00 = len(y_indices)\n",
    "        m10 = np.sum(x_indices)\n",
    "        m01 = np.sum(y_indices)\n",
    "        \n",
    "        # Central moments\n",
    "        mu20 = np.sum((x_indices - center_x) ** 2)\n",
    "        mu02 = np.sum((y_indices - center_y) ** 2)\n",
    "        mu11 = np.sum((x_indices - center_x) * (y_indices - center_y))\n",
    "        \n",
    "        # Angle of the principal axes\n",
    "        if mu20 - mu02 == 0:\n",
    "            theta = 0 if mu11 == 0 else np.pi / 4\n",
    "        else:\n",
    "            theta = 0.5 * np.arctan2(2 * mu11, mu20 - mu02)\n",
    "        \n",
    "        # Convert to degrees\n",
    "        angle_degrees = np.degrees(theta)\n",
    "        \n",
    "        # Rotate and scale\n",
    "        rotated = self.rotate_image(image, angle_degrees)\n",
    "        normalized = self.scale_image(rotated, target_size)\n",
    "        \n",
    "        return normalized\n",
    "    \n",
    "    # ==================== FEATURE EXTRACTION ====================\n",
    "    \n",
    "    def harris_corner_detection(self, image, k=0.04, threshold_ratio=0.01):\n",
    "        \"\"\"Implement Harris corner detection algorithm.\"\"\"\n",
    "        # Convert to grayscale if necessary\n",
    "        if len(image.shape) == 3:\n",
    "            gray = np.mean(image, axis=2).astype(np.uint8)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        # Apply Gaussian filter to reduce noise\n",
    "        smoothed = self.gaussian_filter(gray, kernel_size=5, sigma=1.0)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
    "        sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32)\n",
    "        \n",
    "        height, width = smoothed.shape\n",
    "        Ix = np.zeros_like(smoothed, dtype=np.float32)\n",
    "        Iy = np.zeros_like(smoothed, dtype=np.float32)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        for y in range(1, height-1):\n",
    "            for x in range(1, width-1):\n",
    "                Ix[y, x] = np.sum(smoothed[y-1:y+2, x-1:x+2] * sobel_x)\n",
    "                Iy[y, x] = np.sum(smoothed[y-1:y+2, x-1:x+2] * sobel_y)\n",
    "        \n",
    "        # Compute products of gradients\n",
    "        Ixx = Ix * Ix\n",
    "        Iyy = Iy * Iy\n",
    "        Ixy = Ix * Iy\n",
    "        \n",
    "        # Apply Gaussian window to gradient products\n",
    "        window_size = 5\n",
    "        sigma = 1.0\n",
    "        Ixx = self.gaussian_filter(Ixx, kernel_size=window_size, sigma=sigma)\n",
    "        Iyy = self.gaussian_filter(Iyy, kernel_size=window_size, sigma=sigma)\n",
    "        Ixy = self.gaussian_filter(Ixy, kernel_size=window_size, sigma=sigma)\n",
    "        \n",
    "        # Calculate Harris response\n",
    "        R = np.zeros_like(Ixx, dtype=np.float32)\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                M = np.array([[Ixx[y, x], Ixy[y, x]], [Ixy[y, x], Iyy[y, x]]])\n",
    "                R[y, x] = np.linalg.det(M) - k * (np.trace(M) ** 2)\n",
    "        \n",
    "        # Threshold\n",
    "        threshold = threshold_ratio * np.max(R)\n",
    "        corner_mask = (R > threshold).astype(np.uint8)\n",
    "        \n",
    "        # Non-maximum suppression\n",
    "        corners = []\n",
    "        window_size = 3\n",
    "        pad = window_size // 2\n",
    "        for y in range(pad, height-pad):\n",
    "            for x in range(pad, width-pad):\n",
    "                if corner_mask[y, x] == 1:\n",
    "                    window = R[y-pad:y+pad+1, x-pad:x+pad+1]\n",
    "                    if R[y, x] == np.max(window):\n",
    "                        corners.append((x, y))\n",
    "        \n",
    "        return corners, R\n",
    "    \n",
    "    def count_corners(self, image, k=0.04, threshold_ratio=0.01):\n",
    "        \"\"\"Count corners in the image using Harris corner detector.\"\"\"\n",
    "        corners, _ = self.harris_corner_detection(image, k, threshold_ratio)\n",
    "        return len(corners)\n",
    "    \n",
    "    def calculate_circularity(self, mask):\n",
    "        \"\"\"Calculate circularity of the shape.\"\"\"\n",
    "        # Find contour\n",
    "        edges = self.canny_edge_detection(mask)\n",
    "        \n",
    "        # Calculate perimeter (number of edge pixels)\n",
    "        perimeter = np.sum(edges > 0)\n",
    "        \n",
    "        # Calculate area (number of mask pixels)\n",
    "        area = np.sum(mask > 0)\n",
    "        \n",
    "        # Calculate circularity\n",
    "        if perimeter == 0:  # Handle division by zero\n",
    "            return 0\n",
    "        \n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2)\n",
    "        return circularity\n",
    "    \n",
    "    def calculate_aspect_ratio(self, mask):\n",
    "        \"\"\"Calculate aspect ratio of the bounding box.\"\"\"\n",
    "        # Find non-zero points\n",
    "        y_indices, x_indices = np.where(mask > 0)\n",
    "        \n",
    "        if len(y_indices) == 0 or len(x_indices) == 0:\n",
    "            return 1.0  # Default for empty mask\n",
    "        \n",
    "        # Calculate bounding box\n",
    "        y_min, y_max = np.min(y_indices), np.max(y_indices)\n",
    "        x_min, x_max = np.min(x_indices), np.max(x_indices)\n",
    "        \n",
    "        height = y_max - y_min + 1\n",
    "        width = x_max - x_min + 1\n",
    "        \n",
    "        # Calculate aspect ratio\n",
    "        if height == 0:  # Handle division by zero\n",
    "            return float('inf')\n",
    "        \n",
    "        return width / height\n",
    "    \n",
    "    def calculate_extent(self, mask):\n",
    "        \"\"\"Calculate extent (area / bounding box area).\"\"\"\n",
    "        # Find non-zero points\n",
    "        y_indices, x_indices = np.where(mask > 0)\n",
    "        \n",
    "        if len(y_indices) == 0 or len(x_indices) == 0:\n",
    "            return 0.0  # Default for empty mask\n",
    "        \n",
    "        # Calculate bounding box\n",
    "        y_min, y_max = np.min(y_indices), np.max(y_indices)\n",
    "        x_min, x_max = np.min(x_indices), np.max(x_indices)\n",
    "        \n",
    "        bbox_area = (y_max - y_min + 1) * (x_max - x_min + 1)\n",
    "        object_area = len(y_indices)\n",
    "        \n",
    "        # Calculate extent\n",
    "        if bbox_area == 0:  # Handle division by zero\n",
    "            return 0.0\n",
    "        \n",
    "        return object_area / bbox_area\n",
    "    \n",
    "    def calculate_average_hue(self, image, mask):\n",
    "        \"\"\"Calculate average hue of the object.\"\"\"\n",
    "        # Convert to HSV\n",
    "        hsv = self.rgb_to_hsv(image)\n",
    "        \n",
    "        # Extract hue channel\n",
    "        hue = hsv[:,:,0]\n",
    "        \n",
    "        # Calculate average hue in the masked region\n",
    "        masked_hue = hue[mask > 0]\n",
    "        \n",
    "        if len(masked_hue) == 0:\n",
    "            return 0.0  # Default for empty mask\n",
    "        \n",
    "        # Calculate average, accounting for hue's circular nature\n",
    "        sin_sum = np.sum(np.sin(masked_hue * (2 * np.pi / 180)))\n",
    "        cos_sum = np.sum(np.cos(masked_hue * (2 * np.pi / 180)))\n",
    "        \n",
    "        if cos_sum == 0:\n",
    "            if sin_sum > 0:\n",
    "                avg_hue = 90.0\n",
    "            else:\n",
    "                avg_hue = 270.0\n",
    "        else:\n",
    "            avg_hue = np.arctan2(sin_sum, cos_sum) * (180 / np.pi)\n",
    "            \n",
    "        # Convert to [0, 180] range\n",
    "        avg_hue = (avg_hue + 360) % 180\n",
    "        \n",
    "        return avg_hue\n",
    "    \n",
    "    def extract_features(self, image):\n",
    "        \"\"\"Extract all required features from the image.\"\"\"\n",
    "        # Preprocess the image\n",
    "        filtered = self.gaussian_filter(image, kernel_size=5, sigma=1.0)\n",
    "        \n",
    "        # Convert to HSV and segment\n",
    "        hsv = self.rgb_to_hsv(filtered)\n",
    "        mask = self.segment_by_color(hsv)\n",
    "\n",
    "        num_foreground = np.sum(mask)\n",
    "        if num_foreground < 50:\n",
    "            print(f\" Warning: Very few foreground pixels in HSV mask: {num_foreground}\")\n",
    "        else:\n",
    "            print(f\" HSV mask foreground pixels: {num_foreground}\")\n",
    "\n",
    "        \n",
    "        # Post-process the mask\n",
    "        opened = self.opening(mask, kernel_size=3)\n",
    "        closed = self.closing(opened, kernel_size=3)\n",
    "        cleaned = self.remove_small_components(closed, min_area=100)\n",
    "        filled = self.fill_holes(cleaned)\n",
    "\n",
    "        print(f\" After opening: {np.sum(opened)}, After connected-component filtering: {np.sum(cleaned)}\")\n",
    "        print(f\" After filling holes: {np.sum(filled)}\")\n",
    "        \n",
    "        # Normalize geometry\n",
    "        normalized = self.normalize_geometry(image, filled, target_size=(200, 200))\n",
    "        \n",
    "        # Extract features\n",
    "        corners = self.count_corners(normalized)\n",
    "        circularity = self.calculate_circularity(filled)\n",
    "        aspect_ratio = self.calculate_aspect_ratio(filled)\n",
    "        extent = self.calculate_extent(filled)\n",
    "        avg_hue = self.calculate_average_hue(image, filled)\n",
    "        \n",
    "        features = {\n",
    "            'corner_count': corners,\n",
    "            'circularity': circularity,\n",
    "            'aspect_ratio': aspect_ratio,\n",
    "            'extent': extent,\n",
    "            'avg_hue': avg_hue\n",
    "        }\n",
    "        \n",
    "        return features, normalized, filled\n",
    "    \n",
    "    # ==================== CLASSIFICATION ====================\n",
    "    \n",
    "    def train_classifier(self, images, labels):\n",
    "        \"\"\"Train a simple k-NN classifier using extracted features.\"\"\"\n",
    "        self.features = {}\n",
    "        self.labels = {}\n",
    "        \n",
    "        for i, (image, label) in enumerate(zip(images, labels)):\n",
    "            print(f\"Processing image {i+1}/{len(images)} (class {label})...\")\n",
    "            features, normalized, mask = self.extract_features(image)\n",
    "            print(features)\n",
    "            self.features[i] = features\n",
    "            self.labels[i] = label\n",
    "            \n",
    "            # Store processed image for visualization\n",
    "            self.processed_images[i] = {\n",
    "                'original': image,\n",
    "                'normalized': normalized,\n",
    "                'mask': mask\n",
    "            }\n",
    "        \n",
    "        print(\"Training complete!\")\n",
    "    \n",
    "    def classify(self, image, k=5):\n",
    "        \"\"\"Classify a new image using k-NN.\"\"\"\n",
    "        # Extract features\n",
    "        features, normalized, mask = self.extract_features(image)\n",
    "        \n",
    "        # Calculate distances to all training examples\n",
    "        distances = []\n",
    "        for idx, train_features in self.features.items():\n",
    "            dist = 0\n",
    "            for feature_name in features:\n",
    "                # Calculate distance for each feature (normalized)\n",
    "                feature_diff = features[feature_name] - train_features[feature_name]\n",
    "                dist += (feature_diff ** 2)\n",
    "            dist = np.sqrt(dist)\n",
    "            distances.append((dist, self.labels[idx]))\n",
    "        \n",
    "        # Sort by distance\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        \n",
    "        # Get top k neighbors\n",
    "        neighbors = distances[:k]\n",
    "        \n",
    "        # Count votes for each class\n",
    "        votes = defaultdict(int)\n",
    "        for _, label in neighbors:\n",
    "            votes[label] += 1\n",
    "        \n",
    "        # Find class with most votes\n",
    "        predicted_class = max(votes.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        return predicted_class, normalized, mask\n",
    "    \n",
    "    def evaluate(self, test_images, test_labels):\n",
    "        \"\"\"Evaluate the classifier on test data.\"\"\"\n",
    "        correct = 0\n",
    "        predictions = []\n",
    "        \n",
    "        for i, (image, true_label) in enumerate(zip(test_images, test_labels)):\n",
    "            print(f\"Testing image {i+1}/{len(test_images)}...\")\n",
    "            predicted_label, _, _ = self.classify(image)\n",
    "            predictions.append(predicted_label)\n",
    "            \n",
    "            if predicted_label == true_label:\n",
    "                correct += 1\n",
    "        \n",
    "        accuracy = correct / len(test_images) if len(test_images) > 0 else 0\n",
    "        print(f\"Accuracy: {accuracy:.4f} ({correct}/{len(test_images)})\")\n",
    "        \n",
    "        return accuracy, predictions\n",
    "    \n",
    "    # ==================== VISUALIZATION ====================\n",
    "    \n",
    "    def visualize_preprocessing(self, image_idx):\n",
    "        \"\"\"Visualize preprocessing steps for a given image.\"\"\"\n",
    "        if image_idx not in self.processed_images:\n",
    "            print(f\"Image {image_idx} not found in processed images.\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        axes[0].imshow(self.processed_images[image_idx]['original'])\n",
    "        axes[0].set_title('Original')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(self.processed_images[image_idx]['normalized'])\n",
    "        axes[1].set_title('Normalized')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(self.processed_images[image_idx]['mask'], cmap='gray')\n",
    "        axes[2].set_title('Segmentation Mask')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def visualize_features(self, image_idx):\n",
    "        \"\"\"Visualize features for a given image.\"\"\"\n",
    "        if image_idx not in self.features:\n",
    "            print(f\"Image {image_idx} not found in features.\")\n",
    "            return\n",
    "        \n",
    "        features = self.features[image_idx]\n",
    "        class_id = self.labels[image_idx]\n",
    "        \n",
    "        # Create a bar chart of features\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        feature_names = list(features.keys())\n",
    "        feature_values = list(features.values())\n",
    "        \n",
    "        ax.bar(feature_names, feature_values)\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.set_title(f'Features for Image {image_idx} (Class {class_id}: {self.class_names.get(class_id, \"Unknown\")})')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def visualize_classification(self, image, predicted_class):\n",
    "        \"\"\"Visualize classification result.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(f'Predicted Class: {predicted_class} ({self.class_names.get(predicted_class, \"Unknown\")})')\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def confusion_matrix(self, true_labels, predicted_labels):\n",
    "        \"\"\"Calculate and visualize confusion matrix.\"\"\"\n",
    "        # Find unique classes\n",
    "        unique_classes = sorted(set(true_labels) | set(predicted_labels))\n",
    "        n_classes = len(unique_classes)\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "        class_mapping = {c: i for i, c in enumerate(unique_classes)}\n",
    "        \n",
    "        for true, pred in zip(true_labels, predicted_labels):\n",
    "            cm[class_mapping[true], class_mapping[pred]] += 1\n",
    "        \n",
    "        # Visualize\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        \n",
    "        # Set labels\n",
    "        ax.set(xticks=np.arange(n_classes),\n",
    "               yticks=np.arange(n_classes),\n",
    "               xticklabels=[self.class_names.get(c, f\"Class {c}\") for c in unique_classes],\n",
    "               yticklabels=[self.class_names.get(c, f\"Class {c}\") for c in unique_classes],\n",
    "               title='Confusion Matrix',\n",
    "               ylabel='True label',\n",
    "               xlabel='Predicted label')\n",
    "        \n",
    "        # Rotate x tick labels and set alignment\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        \n",
    "        # Loop over data dimensions and create text annotations\n",
    "        for i in range(n_classes):\n",
    "            for j in range(n_classes):\n",
    "                ax.text(j, i, str(cm[i, j]),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return cm\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = 'dataset'\n",
    "train_csv = os.path.join(dataset_path, 'Train.csv')\n",
    "\n",
    "df = pd.read_csv(train_csv)\n",
    "\n",
    "# Select classes\n",
    "selected_classes = [0, 1, 2, 3, 4, 5, 6]\n",
    "subset_df = df[df['ClassId'].isin(selected_classes)]\n",
    "\n",
    "# Sample 100 images from each class\n",
    "sampled_df = subset_df.groupby('ClassId').apply(lambda x: x.sample(n=125, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# Split into train/test (80/20)\n",
    "train_df = sampled_df.groupby('ClassId').apply(lambda x: x.sample(frac=0.8, random_state=42)).reset_index(drop=True)\n",
    "test_df = sampled_df.drop(train_df.index).reset_index(drop=True)\n",
    "\n",
    "# Load images\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    img_path = os.path.join(dataset_path, row['Path'])\n",
    "    img = np.array(Image.open(img_path))\n",
    "    train_images.append(img)\n",
    "    train_labels.append(row['ClassId'])\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    img_path = os.path.join(dataset_path, row['Path'])\n",
    "    img = np.array(Image.open(img_path))\n",
    "    test_images.append(img)\n",
    "    test_labels.append(row['ClassId'])\n",
    "\n",
    "# Initialize and train classifier\n",
    "classifier = TrafficSignClassifier()\n",
    "classifier.train_classifier(train_images, train_labels)\n",
    "\n",
    "# Evaluate classifier\n",
    "accuracy, predictions = classifier.evaluate(test_images, test_labels)\n",
    "\n",
    "# Visualize results\n",
    "classifier.confusion_matrix(test_labels, predictions)\n",
    "\n",
    "# # Visualize example images\n",
    "# for i in range(5):  # Show first 5 examples\n",
    "#     classifier.visualize_preprocessing(i)\n",
    "#     classifier.visualize_features(i)\n",
    "\n",
    "# # Test on a single example\n",
    "# if len(test_images) > 0:\n",
    "#     test_img = test_images[0]\n",
    "#     true_label = test_labels[0]\n",
    "#     pred_label, norm_img, mask = classifier.classify(test_img)\n",
    "    \n",
    "#     print(f\"True label: {true_label} ({classifier.class_names.get(true_label, 'Unknown')})\")\n",
    "#     print(f\"Predicted label: {pred_label} ({classifier.class_names.get(pred_label, 'Unknown')})\")\n",
    "    \n",
    "#     # Visualize\n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "#     axes[0].imshow(test_img)\n",
    "#     axes[0].set_title(f'Original (True: {classifier.class_names.get(true_label, \"Unknown\")})')\n",
    "#     axes[0].axis('off')\n",
    "    \n",
    "#     axes[1].imshow(norm_img)\n",
    "#     axes[1].set_title(f'Normalized (Pred: {classifier.class_names.get(pred_label, \"Unknown\")})')\n",
    "#     axes[1].axis('off')\n",
    "    \n",
    "#     axes[2].imshow(mask, cmap='gray')\n",
    "#     axes[2].set_title('Segmentation')\n",
    "#     axes[2].axis('off')\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(classifier.features)\n",
    "features_df = features_df.T\n",
    "\n",
    "classifier.labels.values()\n",
    "features_df['label'] = classifier.labels.values()\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ac574d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corner_count</th>\n",
       "      <th>circularity</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>extent</th>\n",
       "      <th>avg_hue</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6233.0</td>\n",
       "      <td>0.365149</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>12.804450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5507.0</td>\n",
       "      <td>0.155582</td>\n",
       "      <td>1.093750</td>\n",
       "      <td>0.279464</td>\n",
       "      <td>21.607603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6569.0</td>\n",
       "      <td>0.199542</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>11.947828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9520.0</td>\n",
       "      <td>0.084618</td>\n",
       "      <td>1.038961</td>\n",
       "      <td>0.380519</td>\n",
       "      <td>3.779365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2905.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4853.0</td>\n",
       "      <td>0.099072</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.159066</td>\n",
       "      <td>34.759983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6532.0</td>\n",
       "      <td>0.164595</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.418347</td>\n",
       "      <td>2.924597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>9759.0</td>\n",
       "      <td>0.103757</td>\n",
       "      <td>1.096154</td>\n",
       "      <td>0.371120</td>\n",
       "      <td>3.477156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6190.0</td>\n",
       "      <td>0.166695</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.381513</td>\n",
       "      <td>177.331434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9440.0</td>\n",
       "      <td>0.123808</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.631905</td>\n",
       "      <td>83.381574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    corner_count  circularity  aspect_ratio    extent     avg_hue  label\n",
       "0         6233.0     0.365149      0.920000  0.680000   12.804450      0\n",
       "1         5507.0     0.155582      1.093750  0.279464   21.607603      0\n",
       "2         6569.0     0.199542      0.961538  0.323077   11.947828      0\n",
       "3         9520.0     0.084618      1.038961  0.380519    3.779365      0\n",
       "4         2905.0     0.000000      1.000000  0.000000    0.000000      0\n",
       "..           ...          ...           ...       ...         ...    ...\n",
       "59        4853.0     0.099072      0.742857  0.159066   34.759983      1\n",
       "60        6532.0     0.164595      0.968750  0.418347    2.924597      1\n",
       "61        9759.0     0.103757      1.096154  0.371120    3.477156      1\n",
       "62        6190.0     0.166695      0.971429  0.381513  177.331434      1\n",
       "63        9440.0     0.123808      0.840000  0.631905   83.381574      1\n",
       "\n",
       "[64 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.labels.values()\n",
    "features_df['label'] = classifier.labels.values()\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df.to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
