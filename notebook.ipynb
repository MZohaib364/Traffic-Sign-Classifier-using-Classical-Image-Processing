{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4387d2",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ce78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2bc2556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_files (path):\n",
    "#     df = pd.read_csv (path) [['Path', 'ClassId']]\n",
    "#     unique_classes = df ['ClassId'].unique ()\n",
    "#     selected_classes = np.random.choice (unique_classes, size=8, replace=False)\n",
    "\n",
    "#     selected_data = pd.DataFrame ()\n",
    "#     for class_id in selected_classes:\n",
    "#         class_images = df [df ['ClassId'] == class_id].sample (n=100)\n",
    "#         selected_data = pd.concat ([selected_data, class_images], ignore_index=True)\n",
    "\n",
    "#     selected_data = selected_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     selected_data = selected_data.sort_values(by=['ClassId', 'Path']).reset_index(drop=True)\n",
    "\n",
    "#     return selected_data\n",
    "\n",
    "# read_files (\"Train.csv\").to_csv (\"train_use.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59ce03c",
   "metadata": {},
   "source": [
    "# Clip Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73d6d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip (image):\n",
    "    image [image < 0] = 0\n",
    "    image [image > 255] = 255\n",
    "\n",
    "    return image.astype (np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba1adf9",
   "metadata": {},
   "source": [
    "# Preprocessing and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58f576cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_filter (image):\n",
    "    image = image.astype (np.float32)\n",
    "    padded = np.pad (image, ((1,1),(1,1)), mode = 'edge')\n",
    "    output = np.zeros_like (image)\n",
    "\n",
    "    for i in range (image.shape [0]):\n",
    "        for j in range (image.shape [1]):\n",
    "            region = padded [i:i+3, j:j+3]\n",
    "            output [i, j] = np.mean (region)\n",
    "\n",
    "    return clip (output).astype (np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "786a3e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel ():\n",
    "    sigma = 1\n",
    "    size = 3\n",
    "\n",
    "    ax = np.linspace (-(size // 2), size // 2, size)\n",
    "    xx, yy = np.meshgrid (ax, ax)\n",
    "    kernel = np.exp (-(xx ** 2 + yy ** 2) / (2 * sigma ** 2))\n",
    "    kernel /= (2 * np.pi * sigma ** 2)\n",
    "    kernel /= np.sum (kernel)\n",
    "    return kernel\n",
    "\n",
    "def gaussian_filter (image):\n",
    "    image = image.astype (np.float32)\n",
    "    kernel = gaussian_kernel ()\n",
    "\n",
    "    a, b = image.shape\n",
    "    output = np.zeros_like (image)\n",
    "\n",
    "    for i in range (a):\n",
    "        for j in range (b):\n",
    "            sum = 0\n",
    "            for k in range (3):\n",
    "                for l in range (3):\n",
    "                    x = i + k - 1\n",
    "                    y = j + l - 1\n",
    "\n",
    "                    if 0 <= x < a and 0 <= y < b:\n",
    "                        sum += image [x, y] * kernel [k, l]\n",
    "            output [i, j] = sum\n",
    "\n",
    "    return clip (output).astype (np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12146a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter (image):\n",
    "    image = image.astype (np.float32)\n",
    "    padded = np.pad (image, ((1,1), (1,1)), mode='edge')\n",
    "    output = np.zeros_like (image)\n",
    "\n",
    "    for i in range (image.shape [0]):\n",
    "        for j in range (image.shape [1]):\n",
    "            region = padded [i : i+3, j : j+3]\n",
    "            output [i, j] = np.median (region)\n",
    "\n",
    "    return clip (output).astype (np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a5a017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_median_filter (image, max_size=7):\n",
    "    image = image.astype (np.float32)\n",
    "    output = image.copy ()\n",
    "    pad = max_size // 2\n",
    "    padded = np.pad (image, pad, mode='edge')\n",
    "\n",
    "    for i in range (image.shape[0]):\n",
    "        for j in range (image.shape[1]):\n",
    "            window_size = 3\n",
    "            while window_size <= max_size:\n",
    "                half = window_size // 2\n",
    "                region = padded [i + pad - half : i + pad + half + 1,\n",
    "                                j + pad - half : j + pad + half + 1]\n",
    "                z_min = np.min (region)\n",
    "                z_max = np.max (region)\n",
    "                z_med = np.median (region)\n",
    "                z_xy = padded [i + pad, j + pad]\n",
    "\n",
    "                A1 = z_med - z_min\n",
    "                A2 = z_med - z_max\n",
    "\n",
    "                if A1 > 0 and A2 < 0:\n",
    "                    B1 = z_xy - z_min\n",
    "                    B2 = z_xy - z_max\n",
    "                    if B1 > 0 and B2 < 0:\n",
    "                        output [i, j] = z_xy\n",
    "                    else:\n",
    "                        output [i, j] = z_med\n",
    "                    break\n",
    "                else:\n",
    "                    window_size += 2\n",
    "\n",
    "            if window_size > max_size:\n",
    "                output [i, j] = z_med\n",
    "\n",
    "    return clip (output).astype (np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c19c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_boost_filter (image, A=1.5):\n",
    "    image = image.astype (np.float32)\n",
    "    blurred = gaussian_filter (image)\n",
    "    mask = image - blurred\n",
    "    output = (A - 1) * image + mask\n",
    "    return clip (output).astype (np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec66b51",
   "metadata": {},
   "source": [
    "# Color Space Conversion and Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d78bf874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsv (image):\n",
    "    image = image.astype (np.float32) / 255.0\n",
    "    r, g, b = image [..., 0], image [..., 1], image [..., 2]\n",
    "    c_max = np.max (image, axis=2)\n",
    "    c_min = np.min (image, axis=2)\n",
    "    delta = c_max - c_min\n",
    "\n",
    "    h = np.zeros_like (c_max)\n",
    "    s = np.zeros_like (c_max)\n",
    "    v = c_max\n",
    "\n",
    "    mask = delta != 0\n",
    "    r_mask = (c_max == r) & mask\n",
    "    g_mask = (c_max == g) & mask\n",
    "    b_mask = (c_max == b) & mask\n",
    "\n",
    "    h [r_mask] = (60 * (g [r_mask] - b [r_mask]) / delta [r_mask]) % 360\n",
    "    h [g_mask] = (60 * (b [g_mask] - r [g_mask]) / delta [g_mask]) + 120\n",
    "    h [b_mask] = (60 * (r [b_mask] - g [b_mask]) / delta [b_mask]) + 240\n",
    "\n",
    "    h [~mask] = 0\n",
    "    s [c_max != 0] = delta [c_max != 0] / c_max [c_max != 0]\n",
    "    s [c_max == 0] = 0\n",
    "\n",
    "    hsv = np.stack ([h, s, v], axis=2)\n",
    "    return hsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "707ec5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_red_blue (hsv):\n",
    "    h, s, v = hsv [..., 0], hsv [..., 1], hsv [..., 2]\n",
    "\n",
    "    red_mask1 = (h >= 0) & (h <= 15) & (s >= 100/255.0) & (v >= 80/255.0)\n",
    "    red_mask2 = (h >= 165) & (h <= 180) & (s >= 0.4) & (v >= 0.3)\n",
    "    red_mask = red_mask1 | red_mask2\n",
    "\n",
    "    blue_mask = (h >= 100) & (h <= 130) & (s >= 0.4) & (v >= 0.3)\n",
    "\n",
    "    mask = red_mask | blue_mask\n",
    "    return (mask * 255).astype (np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f81a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_threshold (image, threshold=127):\n",
    "    binary = np.zeros_like (image, dtype=np.uint8)\n",
    "    binary [image > threshold] = 255\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50e17dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode (image, kernel_size=3):\n",
    "    pad = kernel_size // 2\n",
    "    padded = np.pad (image, pad, mode='edge')\n",
    "    output = np.zeros_like (image)\n",
    "\n",
    "    for i in range (image.shape [0]):\n",
    "        for j in range (image.shape [1]):\n",
    "            region = padded [i:i+kernel_size, j:j+kernel_size]\n",
    "            output [i, j] = np.min (region)\n",
    "    return output\n",
    "\n",
    "def dilate (image, kernel_size=3):\n",
    "    pad = kernel_size // 2\n",
    "    padded = np.pad (image, pad, mode='edge')\n",
    "    output = np.zeros_like (image)\n",
    "\n",
    "    for i in range (image.shape [0]):\n",
    "        for j in range (image.shape [1]):\n",
    "            region = padded [i:i+kernel_size, j:j+kernel_size]\n",
    "            output [i, j] = np.max (region)\n",
    "    return output\n",
    "\n",
    "def opening (image, kernel_size=3):\n",
    "    return dilate (erode (image, kernel_size), kernel_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e69fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_component_filtering (binary_image, area_threshold=300):\n",
    "    h, w = binary_image.shape\n",
    "    labels = np.zeros_like (binary_image, dtype=np.int32)\n",
    "    output = np.zeros_like (binary_image)\n",
    "    label = 1\n",
    "\n",
    "    for i in range (h):\n",
    "        for j in range (w):\n",
    "            if binary_image [i, j] == 255 and labels [i, j] == 0:\n",
    "                stack = [(i, j)]\n",
    "                component = []\n",
    "\n",
    "                while stack:\n",
    "                    x, y = stack.pop ()\n",
    "                    if (0 <= x < h) and (0 <= y < w):\n",
    "                        if binary_image [x, y] == 255 and labels [x, y] == 0:\n",
    "                            labels [x, y] = label\n",
    "                            component.append ((x, y))\n",
    "                            stack.extend ([(x+1,y), (x-1,y), (x,y+1), (x,y-1)])\n",
    "\n",
    "                if len (component) >= area_threshold:\n",
    "                    for (x, y) in component:\n",
    "                        output [x, y] = 255\n",
    "\n",
    "                label += 1\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c421cc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_holes (binary_image):\n",
    "    h, w = binary_image.shape\n",
    "    visited = np.zeros_like (binary_image, dtype=bool)\n",
    "    filled = binary_image.copy ()\n",
    "\n",
    "    stack = []\n",
    "    for i in range (h):\n",
    "        if filled [i, 0] == 0:\n",
    "            stack.append ((i, 0))\n",
    "        if filled [i, w - 1] == 0:\n",
    "            stack.append ((i, w - 1))\n",
    "    for j in range (w):\n",
    "        if filled [0, j] == 0:\n",
    "            stack.append ((0, j))\n",
    "        if filled [h - 1, j] == 0:\n",
    "            stack.append ((h - 1, j))\n",
    "\n",
    "    while stack:\n",
    "        x, y = stack.pop ()\n",
    "        if 0 <= x < h and 0 <= y < w:\n",
    "            if filled [x, y] == 0 and not visited[x, y]:\n",
    "                visited [x, y] = True\n",
    "                stack.extend ([(x+1,y), (x-1,y), (x,y+1), (x,y-1)])\n",
    "\n",
    "    for i in range (h):\n",
    "        for j in range (w):\n",
    "            if not visited [i, j] and filled [i, j] == 0:\n",
    "                filled [i, j] = 255\n",
    "\n",
    "    return filled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5e2b5",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "beb03506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_gradients (image):\n",
    "\n",
    "    Kx = np.array ([[-1, 0, 1],\n",
    "                   [-2, 0, 2],\n",
    "                   [-1, 0, 1]], dtype=np.float32)\n",
    "    Ky = np.array ([[1, 2, 1],\n",
    "                   [0, 0, 0],\n",
    "                   [-1, -2, -1]], dtype=np.float32)\n",
    "\n",
    "    pad = 1\n",
    "    padded = np.pad (image, pad, mode='reflect')\n",
    "    Gx = np.zeros_like (image, dtype=np.float32)\n",
    "    Gy = np.zeros_like (image, dtype=np.float32)\n",
    "\n",
    "    for i in range (image.shape[0]):\n",
    "        for j in range (image.shape[1]):\n",
    "            region = padded [i:i+3, j:j+3]\n",
    "            Gx [i, j] = np.sum (region * Kx)\n",
    "            Gy [i, j] = np.sum (region * Ky)\n",
    "\n",
    "    magnitude = np.sqrt (Gx**2 + Gy**2)\n",
    "    direction = np.arctan2 (Gy, Gx)\n",
    "    \n",
    "    return magnitude, direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e9b91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression (magnitude, direction):\n",
    "    h, w = magnitude.shape\n",
    "    output = np.zeros ((h, w), dtype=np.float32)\n",
    "    angle = np.rad2deg (direction) % 180\n",
    "\n",
    "    for i in range (1, h-1):\n",
    "        for j in range (1, w-1):\n",
    "            q, r = 255, 255\n",
    "\n",
    "            if (0 <= angle [i,j] < 22.5) or (157.5 <= angle [i,j] <= 180):\n",
    "                q = magnitude [i, j+1]\n",
    "                r = magnitude [i, j-1]\n",
    "\n",
    "            elif 22.5 <= angle [i,j] < 67.5:\n",
    "                q = magnitude [i+1, j-1]\n",
    "                r = magnitude [i-1, j+1]\n",
    "            \n",
    "            elif 67.5 <= angle [i,j] < 112.5:\n",
    "                q = magnitude [i+1, j]\n",
    "                r = magnitude [i-1, j]\n",
    "            \n",
    "            elif 112.5 <= angle [i,j] < 157.5:\n",
    "                q = magnitude [i-1, j-1]\n",
    "                r = magnitude [i+1, j+1]\n",
    "\n",
    "            if magnitude [i,j] >= q and magnitude [i,j] >= r:\n",
    "                output [i,j] = magnitude [i,j]\n",
    "            else:\n",
    "                output [i,j] = 0\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a89500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_thresholding (img, low_thresh_ratio=0.05, high_thresh_ratio=0.15):\n",
    "    high_thresh = img.max () * high_thresh_ratio\n",
    "    low_thresh = high_thresh * low_thresh_ratio\n",
    "\n",
    "    strong = 255\n",
    "    weak = 75\n",
    "\n",
    "    result = np.zeros_like (img, dtype=np.uint8)\n",
    "\n",
    "    strong_i, strong_j = np.where (img >= high_thresh)\n",
    "    weak_i, weak_j = np.where ((img <= high_thresh) & (img >= low_thresh))\n",
    "\n",
    "    result [strong_i, strong_j] = strong\n",
    "    result [weak_i, weak_j] = weak\n",
    "\n",
    "    return result, weak, strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "240da195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_tracking_by_hysteresis (img, weak, strong=255):\n",
    "    h, w = img.shape\n",
    "    for i in range (1, h-1):\n",
    "        for j in range (1, w-1):\n",
    "            if img [i,j] == weak:\n",
    "                if ((img [i+1, j-1] == strong) or (img [i+1, j] == strong) or (img [i+1, j+1] == strong)\n",
    "                    or (img [i, j-1] == strong) or (img [i, j+1] == strong)\n",
    "                    or (img [i-1, j-1] == strong) or (img [i-1, j] == strong) or (img [i-1, j+1] == strong)):\n",
    "                    img [i, j] = strong\n",
    "                else:\n",
    "                    img [i, j] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41abf39",
   "metadata": {},
   "source": [
    "# Geometric Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa7a0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image (image, angle_deg):\n",
    "    angle_rad = np.deg2rad (angle_deg)\n",
    "    h, w = image.shape [:2]\n",
    "    center = np.array ([w / 2, h / 2])\n",
    "\n",
    "    R = np.array ([\n",
    "        [np.cos (angle_rad), -np.sin (angle_rad)],\n",
    "        [np.sin (angle_rad),  np.cos (angle_rad)]\n",
    "    ])\n",
    "\n",
    "    coords_y, coords_x = np.meshgrid (np.arange (h), np.arange (w), indexing='ij')\n",
    "    coords = np.stack ([coords_x.ravel (), coords_y.ravel ()], axis=1)\n",
    "\n",
    "    shifted = coords - center\n",
    "    rotated = shifted @ R.T + center\n",
    "    rotated = rotated.round ().astype (int)\n",
    "\n",
    "    output = np.zeros_like (image)\n",
    "    for i, (x_new, y_new) in enumerate (rotated):\n",
    "        x_old, y_old = coords [i]\n",
    "        if 0 <= y_new < h and 0 <= x_new < w:\n",
    "            output [y_new, x_new] = image [y_old, x_old]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4617472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image (image, size=(200, 200)):\n",
    "    h, w = image.shape [:2]\n",
    "    new_h, new_w = size\n",
    "    scale_y, scale_x = h / new_h, w / new_w\n",
    "\n",
    "    y_indices = (np.arange (new_h) * scale_y).astype (int)\n",
    "    x_indices = (np.arange (new_w) * scale_x).astype (int)\n",
    "    \n",
    "    return image [y_indices [:, None], x_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b3c3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform_numpy (image, src_pts, dst_pts, output_size=(200, 200)):\n",
    "    \n",
    "    def compute_homography (src, dst):\n",
    "        A = []\n",
    "        for (x, y), (u, v) in zip (src, dst):\n",
    "            A.append ([-x, -y, -1, 0, 0, 0, x*u, y*u, u])\n",
    "            A.append ([0, 0, 0, -x, -y, -1, x*v, y*v, v])\n",
    "        A = np.array (A)\n",
    "        _, _, Vt = np.linalg.svd (A)\n",
    "        H = Vt [-1].reshape ((3, 3))\n",
    "        return H / H [-1, -1]\n",
    "\n",
    "    src = np.array (src_pts, dtype=np.float32)\n",
    "    dst = np.array (dst_pts, dtype=np.float32)\n",
    "    H = compute_homography (src, dst)\n",
    "\n",
    "    output_h, output_w = output_size\n",
    "    output = np.zeros ((output_h, output_w), dtype=image.dtype)\n",
    "\n",
    "    for i in range (output_h):\n",
    "        for j in range (output_w):\n",
    "            target_coords = np.array ([j, i, 1])\n",
    "            source_coords = np.linalg.inv (H) @ target_coords\n",
    "            source_coords /= source_coords [2]\n",
    "            x, y = int (round (source_coords [0])), int (round (source_coords [1]))\n",
    "            if 0 <= y < image.shape [0] and 0 <= x < image.shape [1]:\n",
    "                output [i, j] = image [y, x]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3bdea2",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f4ee38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve2d (image, kernel):\n",
    "    kh, kw = kernel.shape\n",
    "    pad_h, pad_w = kh // 2, kw // 2\n",
    "    padded = np.pad (image, ((pad_h, pad_h), (pad_w, pad_w)), mode='reflect')\n",
    "    output = np.zeros_like (image, dtype=float)\n",
    "\n",
    "    for i in range (image.shape [0]):\n",
    "        for j in range (image.shape [1]):\n",
    "            region = padded [i:i+kh, j:j+kw]\n",
    "            output [i, j] = np.sum (region * kernel)\n",
    "    return output\n",
    "\n",
    "def harris_corner_count (gray, k=0.04, threshold_ratio=0.01):\n",
    "    sobel_x = np.array ([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    sobel_y = np.array ([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "\n",
    "    Ix = convolve2d (gray, sobel_x)\n",
    "    Iy = convolve2d (gray, sobel_y)\n",
    "\n",
    "    Ixx = Ix * Ix\n",
    "    Iyy = Iy * Iy\n",
    "    Ixy = Ix * Iy\n",
    "\n",
    "    kernel = np.array ([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16\n",
    "\n",
    "    Sxx = convolve2d (Ixx, kernel)\n",
    "    Syy = convolve2d (Iyy, kernel)\n",
    "    Sxy = convolve2d (Ixy, kernel)\n",
    "\n",
    "    detM = Sxx * Syy - Sxy ** 2\n",
    "    traceM = Sxx + Syy\n",
    "    R = detM - k * (traceM ** 2)\n",
    "\n",
    "    threshold = threshold_ratio * np.max (R)\n",
    "    corners = (R > threshold)\n",
    "    return np.sum (corners)\n",
    "\n",
    "def compute_perimeter (binary_mask):\n",
    "    eroded = np.zeros_like (binary_mask)\n",
    "    for i in range (1, binary_mask.shape [0]-1):\n",
    "        for j in range (1, binary_mask.shape[1]-1):\n",
    "            if binary_mask [i, j] == 1 and np.all (binary_mask [i-1:i+2, j-1:j+2] == 1):\n",
    "                eroded [i, j] = 1\n",
    "    perimeter = np.sum (binary_mask) - np.sum (eroded)\n",
    "    return perimeter\n",
    "\n",
    "def extract_features (normalized_rgb, binary_mask, normalized_hsv):\n",
    "    gray = np.mean (normalized_rgb, axis=2).astype (np.float32)\n",
    "\n",
    "    # 1. Corner Count\n",
    "    corners = harris_corner_count (gray)\n",
    "\n",
    "    # 2. Circularity\n",
    "    area = np.sum (binary_mask)\n",
    "    perimeter = compute_perimeter (binary_mask)\n",
    "    circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter != 0 else 0\n",
    "\n",
    "    # 3. Bounding box and Aspect Ratio\n",
    "    ys, xs = np.where (binary_mask == 1)\n",
    "    if len (xs) == 0 or len (ys) == 0:\n",
    "        aspect_ratio = 0\n",
    "        extent = 0\n",
    "    else:\n",
    "        width = xs.max () - xs.min () + 1\n",
    "        height = ys.max () - ys.min () + 1\n",
    "        aspect_ratio = width / height if height != 0 else 0\n",
    "\n",
    "        # 4. Extent\n",
    "        bbox_area = width * height\n",
    "        extent = area / bbox_area if bbox_area != 0 else 0\n",
    "\n",
    "    # 5. Average Hue\n",
    "    hue = normalized_hsv [..., 0]\n",
    "    avg_hue = np.mean (hue [binary_mask == 1]) if np.any (binary_mask == 1) else 0\n",
    "\n",
    "    return {\n",
    "        \"corner_count\": int (corners),\n",
    "        \"circularity\": float (circularity),\n",
    "        \"aspect_ratio\": float (aspect_ratio),\n",
    "        \"extent\": float (extent),\n",
    "        \"average_hue\": float (avg_hue)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c50994",
   "metadata": {},
   "source": [
    "# Image Reading and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527c5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv('dataset/Train.csv')\n",
    "\n",
    "# Select N classes (example: 6 classes)\n",
    "selected_classes = [0, 1, 2, 3, 4, 5, 6]\n",
    "subset_df = df[df['ClassId'].isin(selected_classes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5615c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61cf27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAApACsBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APE9b03UrS4+137STi8d5EvGLH7RzkvlgGywZXwwDFZEYjDAnLoooorU1/UodV1GK4gWRUSytLchwAd0VvHEx4J43ISPbHTpWXRRRWxY23huSzja/wBV1WC6Od8cGmRyovJxhjOpPGP4R6c9ax6KKKKsXtr9jnWL7RBPuijl3wPuUb0V9pP95d21h2YEdqr0UUUUUUUUUUUUUUUUV//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACsAAAApCAAAAACJ/o8XAAAAOUlEQVR4AWP4zzB8AWl+I0H1fwbiFROvkomEmBgEaon3GAn+GlVKTgj8ZyAlPZBjw6ie0RAY7iEAALNyCAPOPAbRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=43x41>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open ('00014.png')\n",
    "gray = image.convert ('L')\n",
    "arr = np.array (gray)\n",
    "\n",
    "output = mean_filter (arr)\n",
    "output = gaussian_filter (output)\n",
    "output = median_filter (output)\n",
    "output = adaptive_median_filter (output)\n",
    "output = high_boost_filter (output)\n",
    "\n",
    "Image.fromarray (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cea6d7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAApACsBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/ANf4laPqtloq6jdzCfbLtdlJxg9OMYA+lcn8PYr9b43CKjRNkBZACvPrk4Aq/rOru9zNG13a+WmSIVG3cx5/LmpPD1kNV8QWkl1dwvcTMB5UYIQKBwuc5GcAccCuu8baTp9nZWunCNIp55S4EKF2WJQc8DkknAyRjn2rTsdHitLGCA+Hb6TYgG8sozx6Z4pfiHD9t8Ez2lq8oWWeKNjJkEDcD37cA15esZ1F10DQn8uziXFzctx5hHX8PbvWz/whPh20sM3F+810R0VwBn6Vl2mi3ehTNrWk30Eaw5GHZWPuAD0Pv1rf8J+JJr/V7/WL2OaSUhUa53gCNC3KhTxnoRz29a7SHxX4fWILHbs6AnDkKd3PXJOTmsTxHr0knhW5t1tkVZBkFpGLcH72OP68+tcBodrFdeH3twxVpXzI4PJHpVKGwgW/nS1jbZGAnyklmP19a7m28Iada/2c+o+Xa20y5FtExMsjep7/AP16s6Vosb+LZNPggS00zcrSwythpB6Y9T+FdcfDOmqSqjaqnaADnAHFc3renabN4WvrqMSwTiTGLh9rEdlwcY9gOfrXl2kagdPlmtHwN2fLJPHtXX6Ei6fo9zGixPdXGSbg87M+lZcGtTeFtROp3d1FeXSoVt4WUnB/vHNbXgSHUfEmr3WuavcXKc+YjIMAHOQo9PYD/wCvXpSaRFKvmMjlmySQ7LknrwDxXIeIit38OruSGOVmZBIFZi3lplgME46YPHPHrXmHhPQ7jxdcy2TssSxIZDOwPygD2rpD8Pl09/JuPGthbuV3rGZGBK9sep6cCnT+EtE0qBBE17reoTDMLfZ2ij4B/vfe6dq3/D2oX1hp66XPdW0EqShhGF+csT0LZwMH8a6ObWfDkkhklIMjAFv3o6kVV8R/8iJdf9g2D+lcd8J/u65/16D+QrK1P/kpdt/uJ/M12HjD/kCR/wDXrF/6CKoeEP8AkWp/94/+hCuVl/1rfWv/2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=43x41>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6fcb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 68, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data = pd.read_csv ('train_use.csv')\n",
    "\n",
    "for i in img_data ['Path']:\n",
    "    image = Image.open (i)\n",
    "    n = np.array (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687768fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
